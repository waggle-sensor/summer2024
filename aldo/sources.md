# Sources for Manual Augmentation and RAG

---
### Models
* [llama3/3.1](https://github.com/ollama/ollama/tree/main)
* [mxbai-embed-large](https://ollama.com/library/mxbai-embed-large)
* [jina](https://jina.ai/embeddings/)

### General
* https://www.ibm.com/topics/large-language-models
* https://www.cloudflare.com/learning/ai/what-is-vector-database/
* https://stancsz.medium.com/prompt-engineering-data-augumentation-d475b8ee4450
* https://aws.amazon.com/what-is/retrieval-augmented-generation/
* https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/
* https://research.ibm.com/blog/retrieval-augmented-generation-RAG
* https://medium.com/@zshariff70/langchain-simple-llm-chains-in-action-bda6950afc71
* https://medium.com/wbaa/a-confidence-score-for-llm-answers-c668844d52c8
* https://github.com/NirDiamant/RAG_Techniques/tree/main

### Sage
* https://sagecontinuum.org
* https://github.com/sagecontinuum
* https://github.com/waggle-sensor/sage-website/tree/main
* https://pypi.org/project/sage-data-client/
  


### Langchain
* https://python.langchain.com/docs/introduction/
* https://python.langchain.com/v0.2/docs/tutorials/rag/
* https://python.langchain.com/v0.1/docs/modules/chains/
* https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb
* https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community
* https://docs.smith.langchain.com/old/cookbook/testing-examples/rag_eval

### Papers
* https://arxiv.org/abs/2312.10997
* https://arxiv.org/abs/2207.05221
* https://arxiv.org/abs/2210.10723